# ğŸ­ Hybrid Emotion Detection from Real-Time Video (MTCNN + Haar Cascade)

This project detects **human emotions in real-time** using a webcam feed.  
It combines **deep learning-based emotion recognition** with **hybrid face detection** â€”  
leveraging **MTCNN (Multi-task Cascaded Convolutional Networks)** for high accuracy and **Haar Cascade** as a fast fallback when MTCNN fails.

---

## ğŸ§  Features
âœ… Real-time webcam emotion detection  
âœ… Hybrid face detection (MTCNN + Haar Cascade fallback)  
âœ… Uses **Mini-XCEPTION** model trained on **FER2013** dataset  
âœ… Displays emotion label and confidence score on screen  
âœ… Works even in low-light or occluded face conditions  

---

## ğŸ§© Tech Stack
- **Python 3.8+**
- **OpenCV** (video and face detection)
- **FER (Facial Expression Recognition)** library (MTCNN-based detection)
- **TensorFlow / Keras** (for Mini-XCEPTION model)
- **NumPy** (data preprocessing)

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/sanjai-cpu/Emotion-Detection-From-Realtime-Video.git
cd Emotion-Detection-From-Realtime-Video
2ï¸âƒ£ Install dependencies
bash
Copy code
pip install -r requirements.txt
If you donâ€™t have a requirements.txt, create one with:

bash
Copy code
opencv-python
fer
tensorflow
numpy
3ï¸âƒ£ Download the model file
Place the pre-trained Mini-XCEPTION model file in the project folder:

Copy code
fer2013_mini_XCEPTION.102-0.66.hdf5
You can download it from:
ğŸ‘‰ Mini-XCEPTION Model (FER2013)

ğŸš€ Usage
Run the program:

bash
Copy code
python emotion_detection.py
Once the webcam window opens:

The system detects your face and predicts your dominant emotion.

Press q to quit the application.

ğŸ“¦ Project Structure
css
Copy code
ğŸ“ Emotion-Detection-From-Realtime-Video/
â”œâ”€â”€ emotion_detection.py          # Main program file
â”œâ”€â”€ fer2013_mini_XCEPTION.102-0.66.hdf5   # Pre-trained model
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ˜„ Supported Emotions
Label	Emotion
0	Angry
1	Disgust
2	Fear
3	Happy
4	Sad
5	Surprise
6	Neutral

ğŸ§  How It Works
Frame Capture: Grabs each frame from webcam feed.

Face Detection:

Tries MTCNN (accurate).

Falls back to Haar Cascade if MTCNN fails.

Preprocessing: Converts the face region to grayscale, resizes to 64Ã—64, and normalizes.

Emotion Prediction: Uses the Mini-XCEPTION model to predict emotion probabilities.

Display: Draws a rectangle and emotion label on the detected face.

ğŸ§© Example Output
csharp
Copy code
Hybrid Emotion Detection with fallback started... Press 'q' to quit.

ğŸ’¡ Future Improvements
Add GPU acceleration for faster inference (TensorRT or ONNX)

Implement multi-face tracking

Integrate with a dashboard for emotion analytics

